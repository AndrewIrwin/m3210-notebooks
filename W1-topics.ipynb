{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47396172-a63f-4175-a7c4-e8ec25149a7b",
   "metadata": {},
   "source": [
    "# Week 1 \n",
    "January 9-13, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397d20f6-4088-42cb-a5f6-1deafcdd62c7",
   "metadata": {},
   "source": [
    "## Welcome\n",
    "\n",
    "What is Numerical Analysis? A combination of ideas about numbers, math, and computing. \n",
    "\n",
    "* Contains definitions, theorems, algorithms, applications.\n",
    "* Mostly focussed on problems from calculus (analysis) and linear algebra such as \n",
    "  * root finding, integration, IVPs, BVPs, solving linear systems, matrix decompositions, eigenvalues and eigenvectors. \n",
    "* Algorithm design, interpretation, analysis, implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400e5ddd-5c7f-40f6-9657-a412ef47f57b",
   "metadata": {},
   "source": [
    "## Introductions\n",
    "\n",
    "Learn as a team. Talk, know something about each other.\n",
    "\n",
    "Me: research, computing, fun + joy in mathematical computing\n",
    "\n",
    "You: name, favourite math course, computing experience (programming languages), what do you hope to learn, how did you decide to take the course?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906dfda8-a88a-41e9-9d93-a35fd7aec08b",
   "metadata": {},
   "source": [
    "## Syllabus\n",
    "\n",
    "From the document. Brightspace. Textbook. Evaluation. Julia. \n",
    "\n",
    "Overview course, favouring breadth and main ideas over tracking down every last detail.\n",
    "\n",
    "Mix of math (ideas, definitions, theorems) and computing (algorithms, implementation). Do most ideas twice, once from each perspective. (Plus twice more: homework, project learning and synthesis).\n",
    "\n",
    "Take advantage of small class: discussion, questions, interactive.\n",
    "\n",
    "How to succeed: learn to write computer code, solve problems, develop skills for independent learning\n",
    "\n",
    "Homework: install Julia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a431d8b0-ccad-47fe-a376-a4dfbfe86116",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "[Chapter 1](https://tobydriscoll.net/fnc-julia/intro/overview.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f942f97-1d6c-4593-a3e4-12aeeeb2aaf5",
   "metadata": {},
   "source": [
    "## Numbers\n",
    "\n",
    "* Integers\n",
    "\n",
    "* Floating point: $\\pm (1+f)\\cdot 2^n$ with sign, significand (mantissa, f), exponent (n)\n",
    "  * $f = \\sum_{i=1}^d b_i 2^{-i}$, $b_i \\in \\{ 0, 1 \\}$ and precision is $d$\n",
    "  * smallest number larger than 1: $1+ 2^{-52}$ (machine $\\epsilon$) \n",
    "  * most real numbers must be rounded to a floating point representation $fl(x)$\n",
    "    * generally $\\left| \\frac{fl(x)-x}{x} \\right| < \\epsilon/2$\n",
    "  * we are used to this with decimal numbers; binary numbers can be confusing\n",
    "    * 0.2 can't be represented exactly as a floating point number\n",
    "\n",
    "* Absolute accuracy: $|\\tilde x - x|$\n",
    "* Relative accuracy: $\\frac{|\\tilde x - x|}{|x|}$\n",
    "* Number of accurate digits: $-\\log_{10}\\frac{|\\tilde x - x|}{|x|}$\n",
    "* Subtractive cancellation: loss of accuracy when two numbers add (or subtract) to give a result much smaller in magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337093b9-da32-479f-9987-c9052ad7dd39",
   "metadata": {},
   "source": [
    "## Condition number\n",
    "\n",
    "Given a real number $x$ and its floating point representation $\\tilde x = fl(x)$\n",
    "\n",
    "$fl(x) = x(1+\\epsilon)$ for some $\\epsilon \\leq \\epsilon_{mach}/2$\n",
    "\n",
    "Ratio of relative errors in $f(x)$ and $x$ is \n",
    "\n",
    "$$\\frac{\\left|\\frac{f(x) -f(\\tilde x)}{f(x)}\\right|}{\\left|\\frac{x-\\tilde x}{x}\\right|}$$\n",
    "\n",
    "which can be simplified to \n",
    "\n",
    "$$\\left| \\frac{f(x) -f(x+\\epsilon x)}{\\epsilon f(x)}\\right|$$\n",
    "\n",
    "Consider the limit as $\\epsilon\\to 0$ (Even with lots of precision, is there a problem?)\n",
    "\n",
    "This is the condition number of a function $f$ at $x$:\n",
    "\n",
    "$$\\kappa_f(x) = \\lim_{\\epsilon\\to 0} \\left| \\frac{f(x) -f(x+\\epsilon x)}{\\epsilon f(x)}\\right|$$\n",
    "\n",
    "$$ = \\left|\\frac{xf'(x)}{f(x)}\\right|$$\n",
    "\n",
    "Example: $f(x) = x-c$. $\\kappa_f(x) = \\left|\\frac{x}{x-c}\\right|$ and if $|x| >> |x-c|$ this is large. then the error in $f(x)$ is large compared to the error in $x$.\n",
    "\n",
    "Big condition number means low accuracy in $f(x)$ even if $x$ is known accurately.\n",
    "\n",
    "Example. $f(x) = cx, c\\neq 0$. $\\kappa_f(x) = 1$.\n",
    "\n",
    "Table in book.\n",
    "\n",
    "Error in $f(x)$ is $\\left| \\frac{f(x+\\epsilon x)-f(x)}{f(x)}\\right| \\approx \\kappa_f(x) |\\epsilon|$.\n",
    "\n",
    "If $\\kappa_f = 10^d$ we expect to lose $d$ digits of accuracy when computing $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49436d4-8164-4dda-a5d3-cce3b04481f6",
   "metadata": {},
   "source": [
    "## More examples of condition numbers\n",
    "\n",
    "$f(x) = \\sin(x)$. $\\kappa_f(x) = |x \\cot(x)|$. The condition number is large if either $x$ is large or if $\\sin(x)$ is close to 0, i.e., at $x=k\\pi$.\n",
    "\n",
    "We anticipate low accuracy for computing $\\sin(10^{15}\\pi)$ and no accuracy for $\\sin(10^{20}\\pi)$.\n",
    "\n",
    "Example. Roots of quadratic polynomials. $p(x) = ax^2 + bx + c$.\n",
    "\n",
    "We know $p(x)=0$ when $x = \\frac{-b \\pm \\sqrt{b^2-4ac}}{2a}$. Suppose $|b|$ is close to the magnitude of the discriminant. Subtractive cancellation can be a problem.\n",
    "\n",
    "Once one root is found, avoiding subtractive cancellation, find the other with $r_2 = c/(ar_1)$. Alternatively multiply the quadratic formula by the radical conjugate to write the second root in a form that does not require subtractive cancellation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d084c0b-5e7d-419c-8195-1917a4a4c688",
   "metadata": {},
   "source": [
    "## Algorithms\n",
    "\n",
    "We define a polynomial as $p(x) = \\sum_{i=0}^{n} a_ix^i$. How to we evauate $p(x)$? Are there more and less accurate ways to do this? Are there ways that take more or fewer computations (called floating point operations)?\n",
    "\n",
    "Common to write the polynomial in Horner form $p(x) = a_0 + x(a_1 + x(a_2 + x(a_3 + \\dots)))$. See code in section 1.3 ([Function 1.3.2](https://tobydriscoll.net/fnc-julia/intro/algorithms.html)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f5e12b-7255-4ad9-9dc9-e89de7c78b8a",
   "metadata": {},
   "source": [
    "## Sensitivity\n",
    "\n",
    "The sensitivity of an algorithm depends on two features: the condition number of the underlying function $f$ being computed, and the condition number of each step in the algorithm.\n",
    "\n",
    "Examine at the condition number for a function $f$, the condition number for all the computational steps to evaluate $f$ (e.g., think quadratic formula), and *think* to try to identify a better algorithm. Generally subtractive cancellation is one primary way accuracy can be lost.\n",
    "\n",
    "It's always valuable to test algorithms (and implementations) with a series of examples with known answers to ensure the accuracy is what should be expected.\n",
    "\n",
    "## Backward error\n",
    "\n",
    "Sometimes the best that can be achieved is a small 'backward error'. Suppose $y=f(x)$ is an exact result. Find a floating point number $\\tilde x$ such that the floating point approximation of $y$ satisfies $\\tilde y = f(\\tilde x)$.\n",
    "\n",
    "If you can find this $\\tilde x$ then the absolute backward error is $|x-\\tilde x|$ and the relative backward error is $\\left|\\frac{x-\\tilde x}{x}\\right|$.\n",
    "\n",
    "Consider the task of generating a polynomial with a given set of roots. If there is a double root (or two roots very close to each other), then the condition number for the problem is large. The roots you find from the polynomial may be quite different from the original roots you start with. But, the coefficients of the original polynomial and the coefficients of the polynomial with the new roots may be very close (small backward error)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d479ea-0676-44ab-8570-f46dd9873433",
   "metadata": {},
   "source": [
    "## Stability\n",
    "\n",
    "If an error in the result of a computation is larger than expected from conditioning, then the algorimthm is said to be unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51899f1-ea0f-4786-a7ca-579ea009ca93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
