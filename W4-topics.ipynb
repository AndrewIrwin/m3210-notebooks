{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ffa907-c2b6-47f9-a015-62c9c5e7f88a",
   "metadata": {},
   "source": [
    "## Root finding\n",
    "\n",
    "Chapter 4. https://tobydriscoll.net/fnc-julia/nonlineqn/overview.html\n",
    "\n",
    "We are trying to solve $f(x) = 0$ where $f$ is written in computer code. The numbers $x$ and $f(x$) are represented in floating point.\n",
    "\n",
    "We want to write a \"general\" algorithm that doesn't need to know anything about the computer code. One exception will be a tool called \"automatic differentiation\" which will come in handy and will be explained as part of Chapter 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e735dda-879a-4524-b454-13ad659fc6c3",
   "metadata": {},
   "source": [
    "## Condition number\n",
    "\n",
    "Write $\\tilde x = x + h$ for the floating point value of $x$. If $x$ is a root, then we can usually only evaluate $f(\\tilde x) = \\epsilon$ where $|\\epsilon|$ is small but in general not exactly 0.\n",
    "\n",
    "Use Taylor's theorem to estimate a relationship between $h$ and $\\epsilon$:\n",
    "\n",
    "$f(x+h) = \\epsilon$ so $f(x) + hf'(x) \\approx \\epsilon$. \n",
    "\n",
    "The condition number of the root finding problem is the relative error in the root ($x$) divided by the relative error in $f(x)$. That's $h/\\epsilon$. Using $f(x) = 0$ and rearranging we obtain $\\kappa = | \\frac{h}{\\epsilon} | =  |\\frac{1}{f'(x)}|$. If the derivative of $f$ is 0 at the root, the condition number is $\\infty$.\n",
    "\n",
    "This means, for example, that functions with double roots may be challenging as the derivative will be zero at the root. Think of $(x-1)^2$.\n",
    "\n",
    "We will often use $f(\\tilde x)$, or $f$ evaluated at our candidate root to approximate the error. This is sometimes called the \"residual\" or \"backward error\" (not the error in x, but the error in $f(x)$). It has the benefit of being easy to evaluate!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5652b3c5-882f-4a20-927b-60d2e28aa58e",
   "metadata": {},
   "source": [
    "## Newton's method\n",
    "\n",
    "We started with a binary search, then used a secant line search. Here we use the derivative instead of the secant slope. \n",
    "\n",
    "Starting at a value $x_0$ we write $f(x_1)$ where $x_1 = x_0 + h$ using a tangent line approximation:\n",
    "\n",
    "$$f(x_1) = f(x_0) + hf'(x_0).$$\n",
    "\n",
    "We want to find an $x_1$ that is close to a root, so we set $f(x_1)=0$ and write $h = -f(x_0)/f'(x_0)$. Since $h$ is the distance between the two guesses we have a formula for our next guess:\n",
    "    \n",
    "$$x_1= x_0 - \\frac{f(x_0)}{f'(x_0)}.$$\n",
    "\n",
    "Clearly we need to know $f'$ and it better not be $0$ anywhere we evaluate it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e39d3bb-c498-4fc5-af4e-3d9192fe6ffb",
   "metadata": {},
   "source": [
    "## Write your own Newton's method.\n",
    "\n",
    "Follow the steps in class: Think. English. Julia. Small steps. Test.\n",
    "\n",
    "Input data: $f$, $f'$, $x_0$.\n",
    "\n",
    "Stop when $f(x)$ is close to 0, or $x_{n+1}-x_n$ is close to 0, or we've taken \"too many\" steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c58d6e65-040b-407f-8351-daee605abc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_newton (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function my_newton(f, df, x0)\n",
    "    tolerance = 1e-15\n",
    "    x1 = 0.0\n",
    "    for i in 1:20\n",
    "        x1 = x0 - f(x0)/df(x0)\n",
    "        if (abs(x1-x0) < tolerance) || (abs(f(x1)) < tolerance)\n",
    "            break\n",
    "        end\n",
    "        x0 = x1\n",
    "    end\n",
    "    x1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99daa269-18db-4b90-b7f3-b2b15fd38e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_newton(x -> x - 2.0, x -> 1, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8a89dbc-9521-4a1b-8c5b-54ec1eac92c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_newton(x -> x^2 - 2.0, x -> 2*x, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2d4361d-c787-4d0b-a8c1-b56f5ed01d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f31a0869-0caa-4e9a-8c59-b2ff1a9156bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2599210498948732"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_newton(x -> x^3 - 2.0, x -> 3*x^2, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9323b639-f692-483b-9eb6-77e1d7a79231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2599210498948732"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.0^(1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddb6a37-b2a4-4ec4-ae40-f80e88ff901b",
   "metadata": {},
   "source": [
    "Modify the code to keep the full sequence $x_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16d0615a-f954-4b7c-af22-d1a3195ed8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_newton2 (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function my_newton2(f, df, x0; tolerance = 1e-15)\n",
    "    sequence = [ x0 ] \n",
    "    for i in 1:20\n",
    "        x1 = x0 - f(x0)/df(x0)\n",
    "        push!(sequence, x1)\n",
    "        if (abs(x1-x0) < tolerance) || (abs(f(x1)) < tolerance)\n",
    "            break\n",
    "        end\n",
    "        x0 = x1\n",
    "    end\n",
    "    sequence\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b087b666-e2b9-4dca-a824-b3dd3cca7f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Vector{Float64}:\n",
       " 1.0\n",
       " 1.5\n",
       " 1.4166666666666667\n",
       " 1.4142156862745099\n",
       " 1.4142135623746899\n",
       " 1.4142135623730951"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = my_newton2(x -> x^2 - 2.0, x -> 2*x, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b451036e-ea03-4b58-8148-8e58d8d61579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Vector{Float64}:\n",
       " 0.41421356237309515\n",
       " 0.08578643762690485\n",
       " 0.002453104293571595\n",
       " 2.1239014147411694e-6\n",
       " 1.5947243525715749e-12\n",
       " 0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs.(s .- sqrt(2)) # error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf4b6c47-fbb9-43d0-b46a-b6e710d67115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Vector{Float64}:\n",
       "  0.382775685337863\n",
       "  1.066581366339708\n",
       "  2.610283987399081\n",
       "  5.672865645795637\n",
       " 11.797314373736969\n",
       " Inf"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-log10.( abs.(s .- sqrt(2)) ) # number of accurate digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55ee2ffe-266b-4898-9f6a-ad5088815728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{BigFloat}:\n",
       " 1.0\n",
       " 1.5\n",
       " 1.416666666666666666666666666666666666666666666666666666666666666666666666666661\n",
       " 1.414215686274509803921568627450980392156862745098039215686274509803921568627451\n",
       " 1.414213562374689910626295578890134910116559622115744044584905019200054371835385\n",
       " 1.414213562373095048801689623502530243614981925776197428498289498623195824228933\n",
       " 1.41421356237309504880168872420969807856967187537723400156101313311326525563035\n",
       " 1.414213562373095048801688724209698078569671875376948073176679737990732478462102"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using BigFloats\n",
    "s = my_newton2(x -> x^2 - 2.0, x -> 2*x, BigFloat(1.0), tolerance = 1e-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8db65f84-2409-43b5-97a9-9435f4929cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{BigFloat}:\n",
       "  0.3827756853378630783193995241920061132387223687070682985559555710056771255439819\n",
       "  1.066581366339707351852537943108505253245634618876245138422338603138462440362357\n",
       "  2.610283987399077141000103789472125815691398101943186141674542846582154033508534\n",
       "  5.672865645792784578031610675292980325422044836658614274589161074076664786250617\n",
       " 11.79727693731540182828937943111739390993500829878534781109792798559911206718055\n",
       " 24.04609886812726521962096106811857676862166931759190182899734977637523982446757\n",
       " 48.54374272975050223206253075446738688311550693137875471666123829095433756505891\n",
       " Inf"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@. -log10(abs(s - sqrt(BigFloat(2.0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec1449d-1da5-4855-b092-da801301438e",
   "metadata": {},
   "source": [
    "## Fixed point iteration\n",
    "\n",
    "Section 4.2.\n",
    "\n",
    "A fixed point $p$ of a function $g$ satisfies $p = g(p)$.\n",
    "\n",
    "A fixed point iteration is a sequence $x_{k+1} = g(x_k)$ with some initial data $x_1$. \n",
    "\n",
    "For what functions and initial data does this series converge?\n",
    "\n",
    "If $|g'(p)|<1$ and $x_1$ is close enough to $p$, the sequence will converge. If $|g'(p)| > 1$ the sequence will diverge.\n",
    "\n",
    "The rate of convergence is characteried by the limit of the ratio of errors $\\epsilon_k = x_k - p$,\n",
    "\n",
    "$$\\lim_{k\\to\\infty} \\frac{\\epsilon_{k+1}}{\\epsilon_k} = \\sigma.$$\n",
    "\n",
    "If $\\sigma<1$ the convergence is linear and the rate is $\\sigma$. \n",
    "\n",
    "Numerically, you can't compute a limit and eventually limits on precision will cause errors in arithmetic to dominate the estimate of the limit. In practice we evaluate the limit by observing a few elements of the series.\n",
    "\n",
    "There is a condition ([Lipshitz](https://mathworld.wolfram.com/LipschitzCondition.html), related to differentiability) which will guarantee convergence. This is one of many versions of the [fixed point theorem](https://mathworld.wolfram.com/FixedPointTheorem.html) ([more](https://en.wikipedia.org/wiki/Fixed-point_theorems)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7a21af-363e-406d-ab79-b8790ab3c4e9",
   "metadata": {},
   "source": [
    "## Secant method\n",
    "\n",
    "Our first use of the secant also required a bracket on the root (low and high estimates). This is not necessary and in fact, not really all that desirable. A better version replaces the derivative in Newton's method with a secant computed on the previous two estimates. You still need two points to start, but you don't attempt to keep a bracket on the root. See Function 4.4.4 from the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03cc163-c07e-4958-be20-9faeb1ca1941",
   "metadata": {},
   "source": [
    "## Supralinear convergence\n",
    "\n",
    "Section 4.4.\n",
    "\n",
    "Superlinear convergence:\n",
    "Suppose a sequence $x_k$ approaches limit $x^*$. If the error sequence $\\epsilon_k=x_k - x^*$ satisfies\n",
    "\n",
    "$$\\lim_{k\\to\\infty} \\frac{|\\epsilon_{k+1}|}{|\\epsilon_k|^\\alpha} = L$$\n",
    "\n",
    "for constants $\\alpha >1$ and $L>0$, then the sequence has **superlinear convergence** with rate $\\alpha$. \n",
    "\n",
    "Quadratic convergence is a particular case of superlinear convergence.\n",
    "\n",
    "The text demonstrates that the rate of convergence for the secant method is the golden ratio $(1+ \\sqrt{5})/2 \\approx 1.618$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bc75bb-c10a-48e5-a445-bd02addfe773",
   "metadata": {},
   "source": [
    "## Multidimensional Newton\n",
    "\n",
    "Section 4.5.\n",
    "\n",
    "Solve a set of equations $f_i(x) = 0$.\n",
    "\n",
    "Use a multidimensional Taylor expansion: $f(x+h) = f(x) + J(x)h + \\dots$ where $J$ is the Jacobian (the matrix of first derivatives $\\frac{\\partial f_i}{\\partial x_j}$ evaluated at $x$.\n",
    "\n",
    "The single variable case translates almost exactly:\n",
    "\n",
    "$$x_{k+1} = x_{k} - J^{-1}(x_k) f(x_k).$$\n",
    "\n",
    "Naturally we will solve a linear system to get the increment to $x_k$ at each step. The sequence will be $x_{k+1} = x_k + s_k$ where $J(x_k) s_k = f(x_k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b625bd04-e72d-42fe-9059-f8f041cc4fcd",
   "metadata": {},
   "source": [
    "## More great stuff\n",
    "\n",
    "Not discussed in the class: Quasi-Newton and Non-linear least squares (sections 4.6, 4.7)\n",
    "\n",
    "Some methods combine features of more than one of these methods: for example use interpolation (secant) or Newton with a starting value to find a bracket, then keep the bracket by carefully updating it.\n",
    "\n",
    "The finite difference methods for the Jacobian and derivative (single variable) are often replaced with \"automatic\" differentiation; we will return to this in the next chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6a0808",
   "metadata": {},
   "source": [
    "One more root finding topic to come: interval arithmetic and root finding. This material is not in the textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d05b43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.4",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
